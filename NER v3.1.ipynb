{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras==1.0.6\n",
    "import numpy as np\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import  Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import tensorflow_hub as hub\n",
    "from keras.layers import Dense,TimeDistributed\n",
    "import keras.layers as layers\n",
    "from keras.models import Model,Sequential\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length range:  144 1\n"
     ]
    }
   ],
   "source": [
    "raw = open('wikigold.conll.txt', 'r').readlines()\n",
    " \n",
    "all_x = []\n",
    "point = []\n",
    "for line in raw:\n",
    "    stripped_line = line.strip().split(' ')\n",
    "    point.append(stripped_line)\n",
    "    if line == '\\n':\n",
    "        all_x.append(point[:-1])\n",
    "        point = []\n",
    "all_x = all_x[:-1]\n",
    " \n",
    "lengths = [len(x) for x in all_x]\n",
    "print('Input sequence length range: ', max(lengths), min(lengths))\n",
    " \n",
    "short_x = [x for x in all_x if len(x) < 64]\n",
    " \n",
    "X = [[c[0] for c in x] for x in short_x]\n",
    "y = [[c[1] for c in y] for y in short_x]\n",
    " \n",
    "all_text = [c for x in X for c in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8285 5\n"
     ]
    }
   ],
   "source": [
    "words = list(set(all_text))\n",
    "word2ind = {word: index for index, word in enumerate(words)}\n",
    "ind2word = {index: word for index, word in enumerate(words)}\n",
    "labels = list(set([c for x in y for c in x]))\n",
    "label2ind = {label: (index + 1) for index, label in enumerate(labels)}\n",
    "ind2label = {(index + 1): label for index, label in enumerate(labels)}\n",
    "print('Vocabulary size:', len(word2ind), len(label2ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 63\n",
      "{'I-LOC': 1, 'I-MISC': 2, 'O': 3, 'I-PER': 4, 'I-ORG': 5}\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(x) for x in X])\n",
    "print('Maximum sequence length:', maxlen)\n",
    "print(label2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x, n):\n",
    "    result = np.zeros(n)\n",
    "    result[x] = 1\n",
    "    return result\n",
    " \n",
    "X_enc = [[word2ind[c] for c in x] for x in X]\n",
    "max_label = max(label2ind.values()) + 1\n",
    "y_enc = [[0] * (maxlen - len(ey)) + [label2ind[c] for c in ey] for ey in y]\n",
    "y_enc = [[encode(c, max_label) for c in ey] for ey in y_enc]\n",
    " \n",
    "X_enc = pad_sequences(X_enc, maxlen=maxlen)\n",
    "y_enc = pad_sequences(y_enc, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing tensor shapes: (1440, 63) (352, 63) (1440, 63, 6) (352, 63, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=11*32, train_size=45*32, random_state=42)\n",
    "print('Training and testing tensor shapes:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    " \n",
    "max_features = len(word2ind)\n",
    "embedding_size = 300\n",
    "hidden_size = 32\n",
    "out_size = len(label2ind) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "#elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "embeddings_ = elmo_model(\n",
    "[\"the cat is on the mat\", \"dogs are in the fog\"],\n",
    "signature=\"default\",\n",
    "as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'module_apply_default_1/aggregation/mul_3:0' shape=(2, 6, 1024) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_inbound_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d41dc16aaf62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtimed_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimed_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 237\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                   \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m                   \u001b[0mnode_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m                   tensor_index=tensor_index)\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1340\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1340\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1340\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdetected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \"\"\"\n\u001b[0;32m-> 1312\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0;31m# Prevent cycles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_inbound_nodes'"
     ]
    }
   ],
   "source": [
    "InputSize = maxlen\n",
    "batch_size = 32\n",
    "input_text = layers.Input(shape=(InputSize,), dtype=tf.string)\n",
    "#embedding = layers.Lambda(ElmoEmbedding, output_shape=(embedding_size,),name='Embedding_1')(input_text)\n",
    "#embedding = layers.Lambda(embeddings_, output_shape=(embedding_size,),name='Embedding_1')(input_text)\n",
    "#None, 63, 300\n",
    "lstm_ = LSTM(hidden_size,batch_size=batch_size, return_sequences=True)(embeddings_)\n",
    "#word_emb: the character-based word representations with shape [batch_size, max_length, 512].\n",
    "#lstm_outputs1: the first LSTM hidden state with shape [batch_size, max_length, 1024].\n",
    "#lstm_outputs2: the second LSTM hidden state with shape [batch_size, max_length, 1024].\n",
    "#elmo: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, 1024]\n",
    "#default: a fixed mean-pooling of all contextualized word representations with shape [batch_size, 1024].\n",
    "\n",
    "timed_ = layers.TimeDistributed(layers.Dense(out_size))(lstm_)\n",
    "pred = layers.Activation('softmax')(timed_)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 262,657\n",
      "Trainable params: 262,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    " \n",
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = layers.Lambda(ElmoEmbedding, output_shape=(1024,))(input_text)\n",
    "dense = layers.Dense(256, activation='relu')(embedding)\n",
    "pred = layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "sentence_input = Input(shape=(X_train.shape[1],), dtype=tf.int64)\n",
    "sentence_embedding = ELMoEmbedding(idx2word=ind2word, output_mode=\"elmo\", trainable=True)(sentence_input) # These two are interchangeable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'el_mo_embedding_1/module_1_apply_tokens/aggregation/mul_3:0' shape=(?, ?, 1024) dtype=float32>>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = Dropout(0.5)(sentence_embedding)\n",
    "lstm_ = LSTM(hidden_size,batch_size=batch_size, return_sequences=True)(sentence_embedding)\n",
    "\n",
    "\n",
    "\n",
    "#hidden = Dense(50, activation='relu')(dropout)\n",
    "#output = Dense(1, activation='sigmoid')(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "timed_ = layers.TimeDistributed(layers.Dense(out_size))(lstm_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = layers.Activation('softmax')(timed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 63)                0         \n",
      "_________________________________________________________________\n",
      "el_mo_embedding_1 (ELMoEmbed (None, 63, 1024)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 63, 32)            135296    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 63, 6)             198       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 6)             0         \n",
      "=================================================================\n",
      "Total params: 135,494\n",
      "Trainable params: 135,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[sentence_input], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "\n",
    "class ELMoEmbedding(Layer):\n",
    "\n",
    "    def __init__(self, idx2word, output_mode=\"default\", trainable=True, **kwargs):\n",
    "        assert output_mode in [\"default\", \"word_emb\", \"lstm_outputs1\", \"lstm_outputs2\", \"elmo\"]\n",
    "        assert trainable in [True, False]\n",
    "        self.idx2word = idx2word\n",
    "        self.output_mode = output_mode\n",
    "        self.trainable = trainable\n",
    "        self.max_length = None\n",
    "        self.word_mapping = None\n",
    "        self.lookup_table = None\n",
    "        self.elmo_model = None\n",
    "        self.embedding = None\n",
    "        super(ELMoEmbedding, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.max_length = input_shape[1]\n",
    "        self.word_mapping = [x[1] for x in sorted(self.idx2word.items(), key=lambda x: x[0])]\n",
    "        self.lookup_table = tf.contrib.lookup.index_to_string_table_from_tensor(self.word_mapping, default_value=\"<UNK>\")\n",
    "        self.lookup_table.init.run(session=K.get_session())\n",
    "        self.elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=self.trainable)\n",
    "        super(ELMoEmbedding, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.cast(x, dtype=tf.int64)\n",
    "        sequence_lengths = tf.cast(tf.count_nonzero(x, axis=1), dtype=tf.int32)\n",
    "        strings = tf.squeeze(self.lookup_table.lookup(x))\n",
    "        inputs = {\n",
    "            \"tokens\": strings,\n",
    "            \"sequence_len\": sequence_lengths\n",
    "        }\n",
    "        return self.elmo_model(inputs, signature=\"tokens\", as_dict=True)[self.output_mode]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.output_mode == \"default\":\n",
    "            return (input_shape[0], 1024)\n",
    "        if self.output_mode == \"word_emb\":\n",
    "            return (input_shape[0], self.max_length, 512)\n",
    "        if self.output_mode == \"lstm_outputs1\":\n",
    "            return (input_shape[0], self.max_length, 1024)\n",
    "        if self.output_mode == \"lstm_outputs2\":\n",
    "            return (input_shape[0], self.max_length, 1024)\n",
    "        if self.output_mode == \"elmo\":\n",
    "            return (input_shape[0], self.max_length, 1024)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'idx2word': self.idx2word,\n",
    "            'output_mode': self.output_mode \n",
    "        }\n",
    "        return list(config.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElmoEmbedding(x):\n",
    "    squeezed = tf.squeeze(tf.cast(x, tf.string), axis=1)\n",
    "    return elmo_model(squeezed, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "  input_text = Input(shape=(1,), dtype=tf.string, name='words_input')\n",
    "  tokens = Lambda(ElmoEmbedding, output_shape=(None,1024), name='word_embeddings')(input_text)\n",
    "sentence_input = Input(shape=(x_train.shape[1],), dtype=tf.int64)\n",
    "sentence_embedding = ELMoEmbedding(idx2word=idx2word, output_mode=\"elmo\", trainable=True)(sentence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 352 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 335s 232ms/step - loss: 0.5306 - val_loss: 0.2595\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 329s 228ms/step - loss: 0.2115 - val_loss: 0.1766\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 321s 223ms/step - loss: 0.1550 - val_loss: 0.1385\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 324s 225ms/step - loss: 0.1264 - val_loss: 0.1183\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 325s 226ms/step - loss: 0.1099 - val_loss: 0.1059\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 325s 226ms/step - loss: 0.0984 - val_loss: 0.0961\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 322s 223ms/step - loss: 0.0890 - val_loss: 0.0886\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 323s 224ms/step - loss: 0.0809 - val_loss: 0.0819\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 324s 225ms/step - loss: 0.0740 - val_loss: 0.0775\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 340s 236ms/step - loss: 0.0682 - val_loss: 0.0728\n",
      "352/352 [==============================] - 70s 199ms/step\n",
      "Raw test score: 0.07278500192544678\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Raw test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(yh, pr):\n",
    "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
    "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
    "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
    "    fyh = [c for row in yh for c in row]\n",
    "    fpr = [c for row in ypr for c in row]\n",
    "    return fyh, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr = model.predict_classes(X_train)\n",
    "y_prob = model.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = y_prob.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 3, 3, 3],\n",
       "       [0, 0, 0, ..., 3, 3, 3],\n",
       "       [0, 0, 0, ..., 0, 0, 3],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 3, 3, 3],\n",
       "       [0, 0, 0, ..., 1, 1, 3],\n",
       "       [0, 0, 0, ..., 3, 1, 3]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 3, 3, 3],\n",
       "       [0, 0, 0, ..., 3, 3, 3],\n",
       "       [0, 0, 0, ..., 0, 0, 3],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 3, 3, 3],\n",
       "       [0, 0, 0, ..., 1, 1, 3],\n",
       "       [0, 0, 0, ..., 3, 1, 3]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pr = model.predict_classes(X_train)\n",
    "yh = y_train.argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9404167790666307\n",
      "Training confusion matrix:\n",
      "[[    0     0     0     0     0     0]\n",
      " [    0   903    10    90    39    74]\n",
      " [    0    85   366   286    35   248]\n",
      " [    0    40    41 24544    16   111]\n",
      " [    0    35     1    62  1083    45]\n",
      " [    1   195    26   271    56   993]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.71780604, 0.82432432, 0.97192413, 0.88120423,\n",
       "        0.67505099]),\n",
       " array([0.        , 0.80913978, 0.35882353, 0.99159664, 0.88336052,\n",
       "        0.64396887]),\n",
       " array([0.        , 0.76074136, 0.5       , 0.98166183, 0.88228106,\n",
       "        0.65914371]),\n",
       " array([    0,  1116,  1020, 24752,  1226,  1542]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fyh, fpr = score(yh, pr)\n",
    "print('Training accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Training confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))\n",
    "precision_recall_fscore_support(fyh, fpr)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.9298578199052133\n",
      "Testing confusion matrix:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   0  191    6   26   15   30]\n",
      " [   0   28   81   82    5   77]\n",
      " [   1    8    4 6142   13   36]\n",
      " [   0   23    1   15  231   13]\n",
      " [   0   31    6   75   23  222]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.6797153 , 0.82653061, 0.96876972, 0.80487805,\n",
       "        0.58730159]),\n",
       " array([0.        , 0.71268657, 0.2967033 , 0.99000645, 0.81625442,\n",
       "        0.62184874]),\n",
       " array([0.        , 0.69581056, 0.43665768, 0.97927296, 0.81052632,\n",
       "        0.60408163]),\n",
       " array([   0,  268,  273, 6204,  283,  357]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = model.predict(X_test) \n",
    "pr = y_prob.argmax(axis=-1)\n",
    "yh = y_test.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print('Testing accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Testing confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))\n",
    "precision_recall_fscore_support(fyh, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "string = \"John was a member of US Army\"\n",
    "wordlist1 = string.split(' ')\n",
    "ip = []\n",
    "for x in wordlist:\n",
    "    ip.append(word2ind[x])\n",
    "i=maxlen-len(ip)\n",
    "temp=[0]*i\n",
    "ip1=temp+ip\n",
    "\n",
    "string = \"US Army is war\"\n",
    "wordlist2 = string.split(' ')\n",
    "ip = []\n",
    "for x in wordlist:\n",
    "    ip.append(word2ind[x])\n",
    "i=maxlen-len(ip)\n",
    "temp=[0]*i\n",
    "ip2=temp+ip\n",
    "\n",
    "\n",
    "input_layer = model.layers[1].input\n",
    "output_layer = model.layers[4].output\n",
    "op = K.function([input_layer], [output_layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'activation_3'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[4].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el_mo_embedding_1'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.backend.tensorflow_backend.Function at 0x7f4c7f018eb8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2642,\n",
       " 7125,\n",
       " 7203,\n",
       " 6516]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxx=[ip1,ip2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt=np.array(xxxxx,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 63)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 6224, 5623, 2336, 4287, 8040, 5001, 1988,\n",
       "        4894, 6168, 4894, 3579,  834, 5309, 1143, 2161, 8124, 6187, 3023,\n",
       "        4836, 4510, 2161, 8124, 3863,  833, 4836, 3801],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 6418,  833, 2970, 5385, 4948, 3452, 3526,\n",
       "        7678, 6189, 3023, 3984,  994, 3023, 2901, 3801],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0, 6835],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        6224, 7401, 8095, 6116, 3446, 1686,    9, 7678, 2807, 3736, 7886,\n",
       "        2019, 5714, 4963, 1602, 5067, 7678, 6560, 3801]], dtype=int32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob2 = model.predict(X_test[10:14]) \n",
    "#pr2 = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = op([ttt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 6)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]\n",
    "out[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'was', 'a', 'member', 'of', 'US', 'Army']\n",
      "['I-PER', 'O', 'O', 'O', 'O', 'O', 'I-ORG']\n"
     ]
    }
   ],
   "source": [
    "i=maxlen-len(ip1)\n",
    "\n",
    "temp = []\n",
    "while i<maxlen:\n",
    "    for j in label2ind:        \n",
    "        #if label2ind[j]==out[0][0][i].tolist().index(max(out[0][0][i])):\n",
    "        if label2ind[j]==out[0][0][i].tolist().index(max(out[0][0][i])):\n",
    "            temp.append(j)\n",
    "    i=i+1\n",
    "print(wordlist1)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US', 'Army', 'is', 'war']\n",
      "['O', 'I-ORG', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "i=maxlen-len(ip2)\n",
    "\n",
    "temp = []\n",
    "while i<maxlen:\n",
    "    for j in label2ind:        \n",
    "        #if label2ind[j]==out[0][0][i].tolist().index(max(out[0][0][i])):\n",
    "        if label2ind[j]==out[0][1][i].tolist().index(max(out[0][1][i])):\n",
    "            temp.append(j)\n",
    "    i=i+1\n",
    "print(wordlist2)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ip1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
