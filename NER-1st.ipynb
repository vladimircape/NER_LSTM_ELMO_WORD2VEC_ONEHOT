{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras==1.0.6\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import  Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length range:  144 1\n"
     ]
    }
   ],
   "source": [
    "raw = open('wikigold.conll.txt', 'r').readlines()\n",
    " \n",
    "all_x = []\n",
    "point = []\n",
    "for line in raw:\n",
    "    stripped_line = line.strip().split(' ')\n",
    "    point.append(stripped_line)\n",
    "    if line == '\\n':\n",
    "        all_x.append(point[:-1])\n",
    "        point = []\n",
    "all_x = all_x[:-1]\n",
    " \n",
    "lengths = [len(x) for x in all_x]\n",
    "print('Input sequence length range: ', max(lengths), min(lengths))\n",
    " \n",
    "short_x = [x for x in all_x if len(x) < 64]\n",
    " \n",
    "X = [[c[0] for c in x] for x in short_x]\n",
    "y = [[c[1] for c in y] for y in short_x]\n",
    " \n",
    "all_text = [c for x in X for c in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8285 5\n"
     ]
    }
   ],
   "source": [
    "words = list(set(all_text))\n",
    "word2ind = {word: index for index, word in enumerate(words)}\n",
    "ind2word = {index: word for index, word in enumerate(words)}\n",
    "labels = list(set([c for x in y for c in x]))\n",
    "label2ind = {label: (index + 1) for index, label in enumerate(labels)}\n",
    "ind2label = {(index + 1): label for index, label in enumerate(labels)}\n",
    "print('Vocabulary size:', len(word2ind), len(label2ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 63\n",
      "{'I-LOC': 1, 'O': 2, 'I-PER': 3, 'I-ORG': 4, 'I-MISC': 5}\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(x) for x in X])\n",
    "print('Maximum sequence length:', maxlen)\n",
    "print(label2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x, n):\n",
    "    result = np.zeros(n)\n",
    "    result[x] = 1\n",
    "    return result\n",
    " \n",
    "X_enc = [[word2ind[c] for c in x] for x in X]\n",
    "max_label = max(label2ind.values()) + 1\n",
    "y_enc = [[0] * (maxlen - len(ey)) + [label2ind[c] for c in ey] for ey in y]\n",
    "y_enc = [[encode(c, max_label) for c in ey] for ey in y_enc]\n",
    " \n",
    "X_enc = pad_sequences(X_enc, maxlen=maxlen)\n",
    "y_enc = pad_sequences(y_enc, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing tensor shapes: (1440, 63) (352, 63) (1440, 63, 6) (352, 63, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=11*32, train_size=45*32, random_state=42)\n",
    "print('Training and testing tensor shapes:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    " \n",
    "max_features = len(word2ind)\n",
    "embedding_size = 300\n",
    "hidden_size = 32\n",
    "out_size = len(label2ind) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen, mask_zero=True))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 63, 300)           2485500   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 63, 32)            42624     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 63, 6)             198       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 63, 6)             0         \n",
      "=================================================================\n",
      "Total params: 2,528,322\n",
      "Trainable params: 2,528,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model.add(TimeDistributedDense(out_size))\n",
    "model.add(TimeDistributed(Dense(out_size)))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 352 samples\n",
      "Epoch 1/10\n",
      "  64/1440 [>.............................] - ETA: 3s - loss: 0.3400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3533 - val_loss: 0.4021\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.2823 - val_loss: 0.3704\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.2195 - val_loss: 0.3433\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 5s 3ms/step - loss: 0.1615 - val_loss: 0.3253\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.1179 - val_loss: 0.3164\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0869 - val_loss: 0.3167\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0660 - val_loss: 0.3123\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0513 - val_loss: 0.3207\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0418 - val_loss: 0.3221\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0345 - val_loss: 0.3352\n",
      "352/352 [==============================] - 0s 421us/step\n",
      "Raw test score: 0.33517230505293066\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Raw test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8576004855678446\n",
      "Training confusion matrix:\n",
      "[[    0     0     0     0     0     0]\n",
      " [    4     8   839     0   265     0]\n",
      " [    1     0 24747     1     3     0]\n",
      " [   33     0   931    85   177     0]\n",
      " [   20     0   952     1   569     0]\n",
      " [   35     0   844     2   115    24]]\n",
      "Testing accuracy: 0.8519972918077183\n",
      "Testing confusion matrix:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   5    2  227    0   34    0]\n",
      " [   7    0 6194    0    2    1]\n",
      " [  19    0  237   11   16    0]\n",
      " [   7    0  266    0   84    0]\n",
      " [   6    0  256    0   10    1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 1.        , 0.86267409, 1.        , 0.57534247,\n",
       "        0.5       ]),\n",
       " array([0.        , 0.00746269, 0.99838814, 0.03886926, 0.23529412,\n",
       "        0.003663  ]),\n",
       " array([0.        , 0.01481481, 0.92558279, 0.07482993, 0.33399602,\n",
       "        0.00727273]),\n",
       " array([   0,  268, 6204,  283,  357,  273]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(yh, pr):\n",
    "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
    "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
    "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
    "    fyh = [c for row in yh for c in row]\n",
    "    fpr = [c for row in ypr for c in row]\n",
    "    return fyh, fpr\n",
    " \n",
    "pr = model.predict_classes(X_train)\n",
    "yh = y_train.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print('Training accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Training confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))\n",
    "precision_recall_fscore_support(fyh, fpr)\n",
    " \n",
    "pr = model.predict_classes(X_test)\n",
    "yh = y_test.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print('Testing accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Testing confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))\n",
    "precision_recall_fscore_support(fyh, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'was', 'a', 'member', 'of', 'US', 'Army']\n",
      "['O', 'O', 'O', 'O', 'O', 'I-ORG']\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "string = \"John was a member of US Army\"\n",
    "wordlist = string.split(' ')\n",
    "ip = []\n",
    "for x in wordlist:\n",
    "    ip.append(word2ind[x])\n",
    "i=maxlen-len(ip)\n",
    "temp=[0]*i\n",
    "ip=temp+ip\n",
    "input_layer = model.layers[0].input\n",
    "output_layer = model.layers[3].output\n",
    "op = K.function([input_layer], [output_layer])\n",
    "out = op([[ip]])\n",
    "temp = []\n",
    "while i<maxlen:\n",
    "    for j in label2ind:\n",
    "        #print(out[0][i].tolist())\n",
    "        if label2ind[j]==out[0][0][i].tolist().index(max(out[0][0][i])):\n",
    "            temp.append(j)\n",
    "    i=i+1\n",
    "print(wordlist)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [1.61958724e-01, 1.62683949e-01, 1.77147254e-01, 1.65883929e-01,\n",
       "        1.67069778e-01, 1.65256396e-01],\n",
       "       [2.02888995e-01, 1.52487129e-01, 1.13231316e-01, 1.90600350e-01,\n",
       "        1.68732822e-01, 1.72059357e-01],\n",
       "       [1.27297463e-02, 2.97078546e-02, 8.53693902e-01, 4.16887067e-02,\n",
       "        2.40306221e-02, 3.81491669e-02],\n",
       "       [4.07752319e-04, 3.36301536e-03, 9.85571027e-01, 3.66112613e-03,\n",
       "        2.49265530e-03, 4.50443896e-03],\n",
       "       [1.59365975e-03, 2.08211653e-02, 9.21404541e-01, 1.53812841e-02,\n",
       "        1.99118573e-02, 2.08873581e-02],\n",
       "       [1.43653841e-03, 2.00346000e-02, 9.24304724e-01, 1.47843966e-02,\n",
       "        2.11698040e-02, 1.82699710e-02],\n",
       "       [1.87548231e-02, 1.43373460e-01, 4.14728701e-01, 1.07245676e-01,\n",
       "        2.09967166e-01, 1.05930142e-01],\n",
       "       [4.01856788e-02, 1.67410702e-01, 2.34305456e-01, 1.49051860e-01,\n",
       "        2.85193741e-01, 1.23852536e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'activation_1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4768,\n",
       " 6816,\n",
       " 2857,\n",
       " 3069,\n",
       " 3651,\n",
       " 3574,\n",
       " 1428]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
