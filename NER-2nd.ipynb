{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Keras==1.0.6\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import  Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length range:  144 1\n"
     ]
    }
   ],
   "source": [
    "raw = open('wikigold.conll.txt', 'r').readlines()\n",
    " \n",
    "all_x = []\n",
    "point = []\n",
    "for line in raw:\n",
    "    stripped_line = line.strip().split(' ')\n",
    "    point.append(stripped_line)\n",
    "    if line == '\\n':\n",
    "        all_x.append(point[:-1])\n",
    "        point = []\n",
    "all_x = all_x[:-1]\n",
    " \n",
    "lengths = [len(x) for x in all_x]\n",
    "print('Input sequence length range: ', max(lengths), min(lengths))\n",
    " \n",
    "short_x = [x for x in all_x if len(x) < 64]\n",
    " \n",
    "X = [[c[0] for c in x] for x in short_x]\n",
    "y = [[c[1] for c in y] for y in short_x]\n",
    " \n",
    "all_text = [c for x in X for c in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8285 5\n"
     ]
    }
   ],
   "source": [
    "words = list(set(all_text))\n",
    "word2ind = {word: index for index, word in enumerate(words)}\n",
    "ind2word = {index: word for index, word in enumerate(words)}\n",
    "labels = list(set([c for x in y for c in x]))\n",
    "label2ind = {label: (index + 1) for index, label in enumerate(labels)}\n",
    "ind2label = {(index + 1): label for index, label in enumerate(labels)}\n",
    "print('Vocabulary size:', len(word2ind), len(label2ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 63\n",
      "{'I-LOC': 1, 'I-PER': 2, 'O': 3, 'I-MISC': 4, 'I-ORG': 5}\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(x) for x in X])\n",
    "print('Maximum sequence length:', maxlen)\n",
    "print(label2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x, n):\n",
    "    result = np.zeros(n)\n",
    "    result[x] = 1\n",
    "    return result\n",
    " \n",
    "X_enc = [[word2ind[c] for c in x] for x in X]\n",
    "max_label = max(label2ind.values()) + 1\n",
    "y_enc = [[0] * (maxlen - len(ey)) + [label2ind[c] for c in ey] for ey in y]\n",
    "y_enc = [[encode(c, max_label) for c in ey] for ey in y_enc]\n",
    " \n",
    "X_enc = pad_sequences(X_enc, maxlen=maxlen)\n",
    "y_enc = pad_sequences(y_enc, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing tensor shapes: (1440, 63) (352, 63) (1440, 63, 6) (352, 63, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=11*32, train_size=45*32, random_state=42)\n",
    "print('Training and testing tensor shapes:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    " \n",
    "max_features = len(word2ind)\n",
    "embedding_size = 128\n",
    "hidden_size = 32\n",
    "out_size = len(label2ind) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VEC_MODEL = 'GoogleNews-vectors-negative300.bin'\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(WORD2VEC_MODEL, binary=True)\n",
    "embedding_weights = np.zeros((max_features,embedding_size))\n",
    "for word,index in word2ind.items():\n",
    "    try:\n",
    "        embedding_weights[index,:]=word2vec[word]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(max_features, embedding_size, input_length=maxlen, mask_zero=True))\n",
    "model.add(Embedding(max_features,embedding_size,input_length=maxlen,weights=[embedding_weights]))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 63, 300)           2485500   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 63, 32)            42624     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 63, 6)             198       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 63, 6)             0         \n",
      "=================================================================\n",
      "Total params: 2,528,322\n",
      "Trainable params: 2,528,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model.add(TimeDistributedDense(out_size))\n",
    "model.add(TimeDistributed(Dense(out_size)))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 352 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.6218 - val_loss: 0.2713\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.2324 - val_loss: 0.2049\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 4s 2ms/step - loss: 0.1810 - val_loss: 0.1683\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.1438 - val_loss: 0.1407\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.1134 - val_loss: 0.1195\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0869 - val_loss: 0.1022\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0650 - val_loss: 0.0901\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0476 - val_loss: 0.0816\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0348 - val_loss: 0.0773\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0262 - val_loss: 0.0753\n",
      "352/352 [==============================] - 0s 435us/step\n",
      "Raw test score: 0.07525161281228065\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Raw test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9889061235500405\n",
      "Training confusion matrix:\n",
      "[[    0     0     0     0     0     0]\n",
      " [    1  1043     1    32     5    34]\n",
      " [    0     0  1205    16     1     4]\n",
      " [    0     7     1 24701    23    20]\n",
      " [    2     9     7    67   920    15]\n",
      " [    0    15     4    52    13  1458]]\n",
      "Testing accuracy: 0.9320243737305348\n",
      "Testing confusion matrix:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   1  164    5   55   11   32]\n",
      " [   0    1  214   49    3   16]\n",
      " [   0    1    5 6162   17   19]\n",
      " [   0   10    2  119  115   27]\n",
      " [   0   10   15   91   13  228]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.88172043, 0.8879668 , 0.95151328, 0.72327044,\n",
       "        0.70807453]),\n",
       " array([0.        , 0.6119403 , 0.75618375, 0.99323017, 0.42124542,\n",
       "        0.63865546]),\n",
       " array([0.        , 0.72246696, 0.81679389, 0.97192429, 0.53240741,\n",
       "        0.67157585]),\n",
       " array([   0,  268,  283, 6204,  273,  357]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(yh, pr):\n",
    "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
    "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
    "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
    "    fyh = [c for row in yh for c in row]\n",
    "    fpr = [c for row in ypr for c in row]\n",
    "    return fyh, fpr\n",
    " \n",
    "pr = model.predict_classes(X_train)\n",
    "yh = y_train.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print('Training accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Training confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))\n",
    "precision_recall_fscore_support(fyh, fpr)\n",
    " \n",
    "pr = model.predict_classes(X_test)\n",
    "yh = y_test.argmax(2)\n",
    "fyh, fpr = score(yh, pr)\n",
    "print('Testing accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Testing confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))\n",
    "precision_recall_fscore_support(fyh, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'was', 'a', 'member', 'of', 'US', 'Army']\n",
      "['I-PER', 'O', 'O', 'O', 'O', 'I-ORG', 'I-ORG']\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "string = \"John was a member of US Army\"\n",
    "wordlist = string.split(' ')\n",
    "ip = []\n",
    "for x in wordlist:\n",
    "    ip.append(word2ind[x])\n",
    "i=maxlen-len(ip)\n",
    "temp=[0]*i\n",
    "ip=temp+ip\n",
    "input_layer = model.layers[0].input\n",
    "output_layer = model.layers[3].output\n",
    "op = K.function([input_layer], [output_layer])\n",
    "out = op([[ip]])\n",
    "temp = []\n",
    "while i<maxlen:\n",
    "    for j in label2ind:\n",
    "        #print(out[0][i].tolist())\n",
    "        if label2ind[j]==out[0][0][i].tolist().index(max(out[0][0][i])):\n",
    "            temp.append(j)\n",
    "    i=i+1\n",
    "print(wordlist)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
